# YAMNet

YAMNet is a pretrained deep net that predicts 521 audio event classes based on
the [AudioSet-YouTube corpus](http://g.co/audioset), and employing the
[Mobilenet_v1](https://arxiv.org/pdf/1704.04861.pdf) depthwise-separable
convolution architecture.

Made by Dan Ellis and Manoj Plakal at Google.
Upstream codebase https://github.com/tensorflow/models/tree/master/research/audioset/yamnet
